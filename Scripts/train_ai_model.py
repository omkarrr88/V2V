"""
V2V BSD â€” AI Model Training Pipeline
=======================================
Trains an XGBoost classifier to predict blind spot alert levels from vehicle
telemetry features. Works as a hybrid system alongside the V2.4 math model:

  - Math Model (CRI): Physics-based, deterministic, interpretable
  - AI Model (XGBoost): Pattern-based, learns from simulation data
  - Hybrid: Both predictions shown on dashboard; AI validates math model

Training Data Source: bsd_metrics.csv (generated by v2v_bsd_simulation.py)

Usage:
    python train_ai_model.py              â€” Train on existing data
    python train_ai_model.py --collect     â€” Run simulation to collect data first
"""

import os
import sys
import json
import argparse
import numpy as np
import pandas as pd
from pathlib import Path

# ML Libraries
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb
from joblib import dump, load


# ============================================================
# CONFIGURATION
# ============================================================
METRICS_FILE = "../Outputs/bsd_metrics.csv"
MODEL_FILE   = "../Outputs/bsd_xgboost_model.pkl"
ENCODER_FILE = "../Outputs/bsd_label_encoder.pkl"
REPORT_FILE  = "../Outputs/bsd_training_report.json"

# Features used for prediction
FEATURE_COLS = [
    'speed',           # Ego vehicle speed (m/s)
    'accel',           # Ego acceleration (m/sÂ²)
    'yaw_rate',        # Ego yaw rate (rad/s)
    'num_targets',     # Number of nearby targets
    'cri_left',        # Math model CRI for left side
    'cri_right',       # Math model CRI for right side
    'signals',         # Turn signal state
]

# Adding derived features for better prediction
DERIVED_FEATURES = [
    'max_cri',         # max(cri_left, cri_right)
    'speed_kmh',       # Speed in km/h
    'abs_accel',       # |acceleration|
    'abs_yaw_rate',    # |yaw_rate|
    'is_braking',      # accel < -1.0
    'is_signaling',    # any turn signal on
    'cri_diff',        # |cri_left - cri_right|
    'has_targets',     # num_targets > 0
    'speed_category',  # 0=slow, 1=medium, 2=fast
]

TARGET_COL = 'alert_level'  # What we predict: 0=SAFE, 1=CAUTION, 2=WARNING, 3=CRITICAL


def add_derived_features(df: pd.DataFrame) -> pd.DataFrame:
    """Add engineered features for better ML prediction."""
    df = df.copy()
    df['max_cri'] = df[['cri_left', 'cri_right']].max(axis=1)
    df['speed_kmh'] = df['speed'] * 3.6
    df['abs_accel'] = df['accel'].abs()
    df['abs_yaw_rate'] = df['yaw_rate'].abs()
    df['is_braking'] = (df['accel'] < -1.0).astype(int)
    df['is_signaling'] = (df['signals'] > 0).astype(int)
    df['cri_diff'] = (df['cri_left'] - df['cri_right']).abs()
    df['has_targets'] = (df['num_targets'] > 0).astype(int)
    df['speed_category'] = pd.cut(df['speed'], bins=[-1, 5, 20, 100], labels=[0, 1, 2]).astype(int)
    return df


def create_target_labels(df: pd.DataFrame) -> pd.Series:
    """
    Create ground truth labels from the highest alert level on either side.
    This is what the V2.4 math model computed â€” the AI learns to replicate it.
    """
    alert_map = {'SAFE': 0, 'CAUTION': 1, 'WARNING': 2, 'CRITICAL': 3}
    
    left_levels = df['alert_left'].map(alert_map).fillna(0).astype(int)
    right_levels = df['alert_right'].map(alert_map).fillna(0).astype(int)
    
    return np.maximum(left_levels, right_levels)


def balance_dataset(X: pd.DataFrame, y: pd.Series) -> tuple:
    """
    Balance the dataset using SMOTE-like oversampling for minority classes.
    If only one class exists (e.g., only SAFE), generate synthetic samples
    for other classes based on CRI thresholds.
    """
    unique_classes = y.unique()
    
    if len(unique_classes) < 2:
        print("âš ï¸  Only one class in data. Generating synthetic training samples...")
        
        # Create synthetic samples for missing classes
        synthetic_rows = []
        n_synthetic = max(100, len(X) // 4)
        
        for target_class in [0, 1, 2, 3]:
            if target_class in unique_classes:
                continue
            
            for _ in range(n_synthetic):
                row = X.iloc[np.random.randint(len(X))].copy()
                
                if target_class == 1:  # CAUTION
                    row['cri_left'] = np.random.uniform(0.30, 0.59)
                    row['cri_right'] = np.random.uniform(0.0, 0.3)
                    row['max_cri'] = max(row['cri_left'], row['cri_right'])
                    row['num_targets'] = max(1, int(row['num_targets']))
                    row['has_targets'] = 1
                elif target_class == 2:  # WARNING
                    row['cri_left'] = np.random.uniform(0.60, 0.79)
                    row['cri_right'] = np.random.uniform(0.30, 0.60)
                    row['max_cri'] = max(row['cri_left'], row['cri_right'])
                    row['speed'] = np.random.uniform(15, 30)
                    row['speed_kmh'] = row['speed'] * 3.6
                    row['num_targets'] = max(2, int(row['num_targets']))
                    row['has_targets'] = 1
                elif target_class == 3:  # CRITICAL
                    row['cri_left'] = np.random.uniform(0.80, 1.0)
                    row['cri_right'] = np.random.uniform(0.60, 1.0)
                    row['max_cri'] = max(row['cri_left'], row['cri_right'])
                    row['speed'] = np.random.uniform(20, 35)
                    row['speed_kmh'] = row['speed'] * 3.6
                    row['abs_accel'] = np.random.uniform(2, 5)
                    row['num_targets'] = max(3, int(row['num_targets']))
                    row['has_targets'] = 1
                    row['is_signaling'] = 1
                
                row['cri_diff'] = abs(row['cri_left'] - row['cri_right'])
                synthetic_rows.append((row, target_class))
        
        if synthetic_rows:
            syn_X = pd.DataFrame([r[0] for r in synthetic_rows], columns=X.columns)
            syn_y = pd.Series([r[1] for r in synthetic_rows])
            X = pd.concat([X, syn_X], ignore_index=True)
            y = pd.concat([y, syn_y], ignore_index=True)
            print(f"   Added {len(synthetic_rows)} synthetic samples")
    
    # Oversample minority classes (cap at 5000 per class for speed)
    class_counts = y.value_counts()
    max_count = min(class_counts.max(), 5000)
    
    balanced_X = []
    balanced_y = []
    
    for cls in y.unique():
        cls_X = X[y == cls]
        cls_y = y[y == cls]
        
        if len(cls_X) < max_count:
            # Oversample by random duplication with noise
            n_needed = max_count - len(cls_X)
            indices = np.random.choice(len(cls_X), n_needed, replace=True)
            extra_X = cls_X.iloc[indices].copy()
            # Add small noise to numerical features
            noise_cols = ['speed', 'accel', 'yaw_rate', 'cri_left', 'cri_right']
            for col in noise_cols:
                if col in extra_X.columns:
                    extra_X[col] += np.random.normal(0, 0.01, len(extra_X))
            extra_X['max_cri'] = extra_X[['cri_left', 'cri_right']].max(axis=1)
            extra_X['cri_diff'] = (extra_X['cri_left'] - extra_X['cri_right']).abs()
            
            balanced_X.append(pd.concat([cls_X, extra_X]))
            balanced_y.append(pd.concat([cls_y, pd.Series([cls]*n_needed)]))
        else:
            balanced_X.append(cls_X)
            balanced_y.append(cls_y)
    
    return pd.concat(balanced_X).reset_index(drop=True), pd.concat(balanced_y).reset_index(drop=True)


def train_model():
    """Train XGBoost model on simulation data."""
    print("=" * 70)
    print("ðŸ¤– V2V BSD â€” AI Model Training Pipeline")
    print("=" * 70)
    
    # â”€â”€ Load Data â”€â”€
    print(f"\nðŸ“‚ Loading data from {METRICS_FILE}...")
    if not os.path.exists(METRICS_FILE):
        print("âŒ No training data found! Run the simulation first:")
        print("   python v2v_bsd_simulation.py --no-gui --steps 3600")
        sys.exit(1)
    
    df = pd.read_csv(METRICS_FILE)
    print(f"   Loaded {len(df)} rows, {df['ego_vid'].nunique()} unique vehicles")
    
    # â”€â”€ Feature Engineering â”€â”€
    print("\nðŸ”§ Engineering features...")
    df = add_derived_features(df)
    y_raw = create_target_labels(df)
    
    all_features = FEATURE_COLS + DERIVED_FEATURES
    available_features = [f for f in all_features if f in df.columns]
    X = df[available_features].copy()
    y = y_raw.copy()
    
    print(f"   Features: {len(available_features)}")
    print(f"   Features: {available_features}")
    print(f"\n   Class distribution (before balancing):")
    label_names = {0: 'SAFE', 1: 'CAUTION', 2: 'WARNING', 3: 'CRITICAL'}
    for cls, count in y.value_counts().sort_index().items():
        print(f"     {label_names.get(cls, cls)}: {count}")
    
    # â”€â”€ Balance Dataset â”€â”€
    print("\nâš–ï¸  Balancing dataset...")
    X_balanced, y_balanced = balance_dataset(X, y)
    print(f"   Balanced size: {len(X_balanced)}")
    print(f"   Class distribution (after balancing):")
    for cls, count in y_balanced.value_counts().sort_index().items():
        print(f"     {label_names.get(cls, cls)}: {count}")
    
    # â”€â”€ Train/Test Split â”€â”€
    X_train, X_test, y_train, y_test = train_test_split(
        X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced
    )
    print(f"\n   Train: {len(X_train)}, Test: {len(X_test)}")
    
    # â”€â”€ Train XGBoost â”€â”€
    print("\nðŸš€ Training XGBoost classifier...")
    model = xgb.XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        min_child_weight=3,
        gamma=0.1,
        reg_alpha=0.1,
        reg_lambda=1.0,
        objective='multi:softmax',
        num_class=4,
        eval_metric='mlogloss',
        random_state=42,
        use_label_encoder=False,
    )
    
    model.fit(
        X_train, y_train,
        eval_set=[(X_test, y_test)],
        verbose=False,
    )
    print("   âœ… Training complete!")
    
    # â”€â”€ Evaluate â”€â”€
    print("\nðŸ“Š Evaluation Results:")
    y_pred = model.predict(X_test)
    
    target_names = [label_names[i] for i in sorted(y_test.unique())]
    report = classification_report(y_test, y_pred, target_names=target_names, 
                                   output_dict=True, zero_division=0)
    report_str = classification_report(y_test, y_pred, target_names=target_names,
                                        zero_division=0)
    print(report_str)
    
    # Cross-validation
    print("   Cross-validation (5-fold):")
    cv_scores = cross_val_score(model, X_balanced, y_balanced, cv=3, scoring='accuracy')
    print(f"   Accuracy: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
    
    # Feature importance
    print("\nðŸ“ˆ Feature Importance:")
    importances = dict(zip(available_features, model.feature_importances_))
    sorted_imp = sorted(importances.items(), key=lambda x: x[1], reverse=True)
    for feat, imp in sorted_imp:
        bar = 'â–ˆ' * int(imp * 50)
        print(f"   {feat:20s} {imp:.4f} {bar}")
    
    # â”€â”€ Save Model â”€â”€
    print(f"\nðŸ’¾ Saving model to {MODEL_FILE}...")
    dump(model, MODEL_FILE)
    
    # Save feature list for inference
    model_info = {
        'features': available_features,
        'label_map': label_names,
        'accuracy': float(cv_scores.mean()),
        'cv_std': float(cv_scores.std()),
        'n_training_samples': len(X_balanced),
        'n_classes': len(y_balanced.unique()),
        'feature_importance': {k: float(v) for k, v in importances.items()},
        'classification_report': report,
    }
    with open(REPORT_FILE, 'w') as f:
        json.dump(model_info, f, indent=2)
    
    print(f"   Model saved: {MODEL_FILE}")
    print(f"   Report saved: {REPORT_FILE}")
    
    print("\n" + "=" * 70)
    print(f"âœ… AI Model Training Complete!")
    print(f"   Accuracy: {cv_scores.mean():.2%} Â± {cv_scores.std():.2%}")
    print(f"   Classes: {list(label_names.values())}")
    print("=" * 70)
    
    return model


class BSDPredictor:
    """
    AI model wrapper for use in the simulation loop.
    Predicts alert levels from vehicle telemetry features.
    """
    
    def __init__(self, model_path: str = MODEL_FILE, report_path: str = REPORT_FILE):
        self.model = None
        self.features = None
        self.label_map = {0: 'SAFE', 1: 'CAUTION', 2: 'WARNING', 3: 'CRITICAL'}
        
        try:
            self.model = load(model_path)
            with open(report_path, 'r') as f:
                info = json.load(f)
            self.features = info.get('features', FEATURE_COLS + DERIVED_FEATURES)
            print(f"ðŸ¤– AI model loaded: {model_path}")
            print(f"   Accuracy: {info.get('accuracy', 'unknown'):.2%}")
        except FileNotFoundError:
            print(f"âš ï¸  AI model not found at {model_path}. Running without AI predictions.")
        except Exception as e:
            print(f"âš ï¸  Failed to load AI model: {e}")
    
    def predict(self, speed: float, accel: float, yaw_rate: float,
                num_targets: int, cri_left: float, cri_right: float,
                signals: int) -> dict:
        """
        Predict alert level from vehicle telemetry.
        
        Returns:
            dict with 'ai_alert' (str), 'ai_confidence' (float), 'ai_probs' (list)
        """
        if self.model is None:
            return {'ai_alert': 'N/A', 'ai_confidence': 0.0, 'ai_probs': []}
        
        # Create feature row
        row = {
            'speed': speed, 'accel': accel, 'yaw_rate': yaw_rate,
            'num_targets': num_targets, 'cri_left': cri_left, 'cri_right': cri_right,
            'signals': signals,
            'max_cri': max(cri_left, cri_right),
            'speed_kmh': speed * 3.6,
            'abs_accel': abs(accel),
            'abs_yaw_rate': abs(yaw_rate),
            'is_braking': 1 if accel < -1.0 else 0,
            'is_signaling': 1 if signals > 0 else 0,
            'cri_diff': abs(cri_left - cri_right),
            'has_targets': 1 if num_targets > 0 else 0,
            'speed_category': 0 if speed < 5 else (1 if speed < 20 else 2),
        }
        
        # Select features in correct order
        X = pd.DataFrame([{f: row.get(f, 0) for f in self.features}])
        
        try:
            pred = int(self.model.predict(X)[0])
            probs = self.model.predict_proba(X)[0].tolist()
            confidence = max(probs)
            alert = self.label_map.get(pred, 'SAFE')
        except Exception:
            alert = 'N/A'
            confidence = 0.0
            probs = []
        
        return {
            'ai_alert': alert,
            'ai_confidence': confidence,
            'ai_probs': probs,
        }


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--collect", action="store_true", 
                        help="Run simulation to collect data before training")
    args = parser.parse_args()
    
    if args.collect:
        print("ðŸ“¡ Collecting training data via simulation...")
        import subprocess
        subprocess.run([sys.executable, "v2v_bsd_simulation.py", "--no-gui", "--steps", "3600"])
        print()
    
    train_model()
