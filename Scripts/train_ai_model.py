"""
V2V BSD ‚Äî AI Model Training Pipeline
=======================================
Trains an XGBoost classifier to predict blind spot alert levels from vehicle
telemetry features. Works as a hybrid system alongside the V3.0 math model:

  - Math Model (CRI): Physics-based, deterministic, interpretable
  - AI Model (XGBoost): Pattern-based, learns from simulation data
  - Hybrid: Both predictions shown on dashboard; AI validates math model

Training Data Source: bsd_metrics.csv (generated by v2v_bsd_simulation.py)

Usage:
    python train_ai_model.py              ‚Äî Train on existing data
    python train_ai_model.py --collect     ‚Äî Run simulation to collect data first
"""

import os
import sys
import json
import argparse
import numpy as np
import pandas as pd
from pathlib import Path

# Configure stdout to handle utf-8 safely in Windows terminals
if hasattr(sys.stdout, 'reconfigure'):
    sys.stdout.reconfigure(encoding='utf-8')

# ML Libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import xgboost as xgb
from joblib import dump, load


# ============================================================
# CONFIGURATION
# ============================================================
METRICS_FILE = "../Outputs/bsd_metrics.csv"
MODEL_FILE   = "../Outputs/bsd_xgboost_model.json"
ENCODER_FILE = "../Outputs/bsd_label_encoder.pkl"
REPORT_FILE  = "../Outputs/bsd_training_report.json"

# Features used for prediction
FEATURE_COLS = [
    'speed',           # Ego speed (m/s)
    'accel',           # Ego acceleration
    'yaw_rate',        # Ego yaw rate
    'num_targets',     # Nearby V2V targets
    'signals',         # Turn signal state
    'max_gap',         # Closest target longitudinal gap (m)
    'rel_speed',       # Relative speed to closest threat target (m/s)
    'max_plr',         # Maximum PLR among active targets
    'k_lost_max',      # Max consecutive lost packets
]

# Adding derived features for better prediction
DERIVED_FEATURES = [
    'speed_kmh',       # Speed in km/h
    'abs_accel',       # |acceleration|
    'abs_yaw_rate',    # |yaw_rate|
    'is_braking',      # accel < -1.0
    'is_signaling',    # any turn signal on
    'has_targets',     # num_targets > 0
    'speed_category',  # 0=slow, 1=medium, 2=fast
    'closing_speed',   # Equivalent to rel_speed
]

# NOTE: target_angle is computed externally (by sim from GPS positions) and logged to CSV,
# but is NOT included here because DERIVED_FEATURES must only contain features that
# add_derived_features() can compute from raw BSM telemetry alone.
# For realtime deployment, this feature would require inter-vehicle position data
# which is already captured indirectly through max_gap and other proximity features.

TARGET_COL = 'alert_level'  # What we predict: 0=SAFE, 1=CAUTION, 2=WARNING, 3=CRITICAL


def add_derived_features(df: pd.DataFrame) -> pd.DataFrame:
    """Add engineered features for better ML prediction."""
    df = df.copy()
    df['speed_kmh'] = df['speed'] * 3.6
    df['abs_accel'] = df['accel'].abs()
    df['abs_yaw_rate'] = df['yaw_rate'].abs()
    df['is_braking'] = (df['accel'] < -1.0).astype(int)
    df['is_signaling'] = (df['signals'] > 0).astype(int)
    df['has_targets'] = (df['num_targets'] > 0).astype(int)
    df['speed_category'] = pd.cut(df['speed'], bins=[-1, 5, 20, 100], labels=[0, 1, 2]).astype(int)
    if 'rel_speed' in df.columns:
        df['closing_speed'] = df['rel_speed']
    else:
        df['closing_speed'] = 0.0
    return df



def create_target_labels(df: pd.DataFrame):
    """
    Generate ground truth alerts that exactly match the Mathematical Model's CRI.
    This ensures the 'Model Sync %' measures the AI's ability to replicate the physics engine.
    """
    labels = pd.Series(0, index=df.index)
    
    # Use the maximum CRI from either side logged by the simulation
    # If one side is missing (NaN), treat it as 0
    c_l = df.get('cri_left', 0.0).fillna(0.0)
    c_r = df.get('cri_right', 0.0).fillna(0.0)
    c = np.maximum(c_l, c_r)
    
    # Standard BSD Thresholds
    labels[c >= 0.3] = 1 # CAUTION
    labels[c >= 0.6] = 2 # WARNING
    labels[c >= 0.8] = 3 # CRITICAL
    
    return labels


def get_class_weights(y: pd.Series) -> dict:
    """
    Compute inverse-frequency class weights to handle imbalance.
    No data fabrication ‚Äî XGBoost handles imbalance natively via scale_pos_weight.
    Returns dict of {class_int: weight} for use in sample_weight.
    """
    counts = y.value_counts()
    total = len(y)
    weights = {cls: total / (len(counts) * cnt) for cls, cnt in counts.items()}
    return weights


def train_model(df=None, model_out_path=MODEL_FILE, report_out_path=REPORT_FILE):
    """Train XGBoost model on simulation data."""
    print("=" * 70)
    print("ü§ñ V2V BSD ‚Äî AI Model Training Pipeline")
    print("=" * 70)
    
    # ‚îÄ‚îÄ Load Data ‚îÄ‚îÄ
    if df is None:
        print(f"\nüìÇ Loading data from {METRICS_FILE}...")
        if not os.path.exists(METRICS_FILE):
            print("‚ùå No training data found! Run the simulation first:")
            print("   python v2v_bsd_simulation.py --no-gui --steps 3600")
            sys.exit(1)
        df = pd.read_csv(METRICS_FILE)
    print(f"   Loaded {len(df)} rows, {df['ego_vid'].nunique() if 'ego_vid' in df.columns else 'synthetic'} unique vehicles")
    
    # ‚îÄ‚îÄ Feature Engineering ‚îÄ‚îÄ
    print("\nüîß Engineering features...")
    df = add_derived_features(df)
    y_raw = create_target_labels(df)
    
    all_features = FEATURE_COLS + DERIVED_FEATURES
    available_features = [f for f in all_features if f in df.columns]
    X = df[available_features].copy()
    y = y_raw.copy()
    
    print(f"   Features: {len(available_features)}")
    print(f"   Features: {available_features}")
    print(f"\n   Class distribution (labels from physics model intermediates):")
    label_names = {0: 'SAFE', 1: 'CAUTION', 2: 'WARNING', 3: 'CRITICAL'}
    for cls, count in y.value_counts().sort_index().items():
        print(f"     {label_names.get(cls, cls)}: {count}")
    
    # ‚îÄ‚îÄ Train/Test Split ‚îÄ‚îÄ
    print("\n   Performing stratified train/test split...")
    X_train_raw, X_test, y_train_raw, y_test = train_test_split(
        X, y, test_size=0.25, random_state=42, stratify=y
    )
    
    # ‚îÄ‚îÄ Synthetic Class Injection ‚îÄ‚îÄ
    # Guarantee all 4 classes are present so num_class=4 works correctly
    present_classes = y_train_raw.unique()
    missing_classes = [c for c in [0, 1, 2, 3] if c not in present_classes]
    if missing_classes:
        print(f"\nüíâ Injecting synthetic samples for missing classes: {missing_classes}")
        synthetic_X = []
        synthetic_y = []
        dummy_row = X_train_raw.iloc[-1].copy()
        for c in missing_classes:
            synthetic_X.append(dummy_row)
            synthetic_y.append(c)
        X_train_raw = pd.concat([X_train_raw, pd.DataFrame(synthetic_X, columns=X_train_raw.columns)], ignore_index=True)
        y_train_raw = pd.concat([y_train_raw, pd.Series(synthetic_y)], ignore_index=True)

    # ‚îÄ‚îÄ Compute Sample Weights ‚îÄ‚îÄ
    print("\n‚öñÔ∏è  Computing sample weights...")
    class_weights = get_class_weights(y_train_raw)
    sample_weights = y_train_raw.map(class_weights).fillna(1.0)
    
    X_train = X_train_raw
    y_train = y_train_raw
    
    print(f"   Train size: {len(X_train)}")
    print(f"   Test size: {len(X_test)} (Unbalanced true chronological)")
    
    # ‚îÄ‚îÄ Train XGBoost ‚îÄ‚îÄ
    print("\nüöÄ Training XGBoost classifier...")
    model = xgb.XGBClassifier(
        n_estimators=200,
        max_depth=6,
        learning_rate=0.1,
        subsample=0.8,
        colsample_bytree=0.8,
        min_child_weight=3,
        gamma=0.1,
        reg_alpha=0.1,
        reg_lambda=1.0,
        objective='multi:softprob',
        num_class=4,
        eval_metric='mlogloss',
        random_state=42,
        use_label_encoder=False,
    )
    
    model.fit(
        X_train, y_train,
        sample_weight=sample_weights,
        eval_set=[(X_test, y_test)],
        verbose=False,
    )
    print("   ‚úÖ Training complete!")
    
    # ‚îÄ‚îÄ Evaluate ‚îÄ‚îÄ
    print("\nüìä Evaluation Results:")
    y_pred = model.predict_proba(X_test).argmax(axis=1)
    
    target_names = [label_names[i] for i in sorted(y_test.unique())]
    report = classification_report(y_test, y_pred, target_names=target_names, 
                                   output_dict=True, zero_division=0)
    report_str = classification_report(y_test, y_pred, target_names=target_names,
                                        zero_division=0)
    print(report_str)
    
    # ‚îÄ‚îÄ CRITICAL class specific recall (the metric that matters most for safety) ‚îÄ‚îÄ
    from sklearn.metrics import precision_score, recall_score
    crit_mask = (y_test == 3)
    if crit_mask.sum() > 0:
        p3 = precision_score(y_test, y_pred, labels=[3], average='micro', zero_division=0)
        r3 = recall_score   (y_test, y_pred, labels=[3], average='micro', zero_division=0)
        n3 = int(crit_mask.sum())
        print(f"\n‚ö†Ô∏è  CRITICAL CLASS (label=3): Precision={p3:.4f}  Recall={r3:.4f}  Support={n3}")
        if r3 < 0.50:
            print("   ‚õî CRITICAL recall < 50% ‚Äî model misses most imminent collisions.")
            print("   Run longer simulation to generate more CRITICAL samples.")
        elif r3 < 0.70:
            print("   ‚ö†Ô∏è  CRITICAL recall below 70% ‚Äî acceptable for early-stage, improvable.")
        else:
            print(f"   ‚úÖ CRITICAL recall {r3:.1%} ‚Äî strong detection of imminent collisions.")
    else:
        print("\n‚ö†Ô∏è  No CRITICAL class samples in test set ‚Äî run longer simulation first.")
    
    # Cross-validation
    print("   Note: K-Fold cross-validation is disabled for chronological data.")
    cv_scores = np.array([model.score(X_test, y_test)])
    print(f"   Holdout Test Accuracy: {cv_scores.mean():.4f}")
    
    # Feature importance
    print("\nüìà Feature Importance:")
    importances = dict(zip(available_features, model.feature_importances_))
    sorted_imp = sorted(importances.items(), key=lambda x: x[1], reverse=True)
    for feat, imp in sorted_imp:
        bar = '‚ñà' * int(imp * 50)
        print(f"   {feat:20s} {imp:.4f} {bar}")
        
    import pathlib
    imp_records = sorted(zip(available_features, model.feature_importances_),
                         key=lambda x: x[1], reverse=True)
    imp_df = pd.DataFrame(imp_records, columns=['feature', 'importance'])
    imp_path = pathlib.Path(__file__).parent.parent / 'Outputs' / 'feature_importance.csv'
    imp_path.parent.mkdir(parents=True, exist_ok=True)
    imp_df.to_csv(imp_path, index=False)
    print(f"\n   Feature importances saved ‚Üí {imp_path}")
    print(f"   Top 3 features: " + ", ".join(f"{r['feature']}={r['importance']:.3f}" for _, r in imp_df.head(3).iterrows()))
    
    # ‚îÄ‚îÄ Save Model ‚îÄ‚îÄ
    print(f"\nüíæ Saving model to {model_out_path}...")
    model.save_model(model_out_path)
    
    # Save feature list for inference
    model_info = {
        'features': available_features,
        'label_map': label_names,
        'accuracy': float(cv_scores.mean()),
        'cv_std': float(cv_scores.std()),
        'n_training_samples': len(X_train),
        'n_classes': len(y_train_raw.unique()),
        'feature_importance': {k: float(v) for k, v in importances.items()},
        'classification_report': report,
    }
    with open(report_out_path, 'w') as f:
        json.dump(model_info, f, indent=2)
    
    print(f"   Model saved: {model_out_path}")
    print(f"   Report saved: {report_out_path}")
    
    print("\n" + "=" * 70)
    print(f"‚úÖ AI Model Training Complete!")
    print(f"   Accuracy: {cv_scores.mean():.2%} ¬± {cv_scores.std():.2%}")
    print(f"   Classes: {list(label_names.values())}")
    print("=" * 70)
    
    return model


class BSDPredictor:
    """
    AI model wrapper for use in the simulation loop.
    Predicts alert levels from vehicle telemetry features.
    """
    
    def __init__(self, model_path: str = MODEL_FILE, report_path: str = REPORT_FILE):
        self.model = None
        self.features = None
        self.label_map = {0: 'SAFE', 1: 'CAUTION', 2: 'WARNING', 3: 'CRITICAL'}
        
        try:
            self.model = xgb.XGBClassifier()
            self.model.load_model(model_path)
            with open(report_path, 'r') as f:
                info = json.load(f)
            self.features = info.get('features', FEATURE_COLS + DERIVED_FEATURES)
            print(f"ü§ñ AI model loaded: {model_path}")
            print(f"   Accuracy: {info.get('accuracy', 'unknown'):.2%}")
        except FileNotFoundError:
            print(f"‚ö†Ô∏è  AI model not found at {model_path}. Running without AI predictions.")
        except Exception as e:
            print(f"‚ö†Ô∏è  Failed to load AI model: {e}")
    
    def predict(self, speed: float, accel: float, yaw_rate: float,
                num_targets: int, max_gap: float, rel_speed: float,
                max_plr: float, k_lost_max: int, signals: int,
                target_angle: float = 0.0) -> dict:
        """
        Predict alert level from vehicle telemetry.
        
        Returns:
            dict with 'ai_alert' (str), 'ai_confidence' (float), 'ai_probs' (list)
        """
        if self.model is None:
            return {'ai_alert': 'N/A', 'ai_confidence': 0.0, 'ai_probs': []}
        
        row = {
            'speed': speed, 'accel': accel, 'yaw_rate': yaw_rate,
            'num_targets': num_targets,
            'signals': signals,
            'max_gap': max_gap,
            'rel_speed': rel_speed,
            'max_plr': max_plr,
            'k_lost_max': k_lost_max,
            'speed_kmh': speed * 3.6,
            'abs_accel': abs(accel),
            'abs_yaw_rate': abs(yaw_rate),
            'is_braking': 1 if accel < -1.0 else 0,
            'is_signaling': 1 if signals > 0 else 0,
            'has_targets': 1 if num_targets > 0 else 0,
            'speed_category': 0 if speed < 5 else (1 if speed < 20 else 2),
            'closing_speed': rel_speed,
            'target_angle': target_angle,
        }
        
        # Select features in correct order
        X = pd.DataFrame([{f: row.get(f, 0) for f in self.features}])
        
        try:
            probs = self.model.predict_proba(X)[0].tolist()
            pred = int(probs.index(max(probs)))
            confidence = max(probs)
            alert = self.label_map.get(pred, 'SAFE')
            crit_prob = probs[3] if len(probs) > 3 else 0.0
        except Exception:
            alert = 'N/A'
            confidence = 0.0
            probs = []
            crit_prob = 0.0
        
        return {
            'ai_alert': alert,
            'ai_confidence': confidence,
            'ai_probs': probs,
            'ai_critical_prob': crit_prob,
        }

    def batch_predict(self, feature_rows: list) -> list:
        """
        Batch predict for multiple vehicles in ONE XGBoost inference call.
        ~80x faster than calling predict() for each vehicle individually.
        
        Args:
            feature_rows: List of dicts, one per vehicle (keys = feature names)
        Returns:
            List of result dicts in same order as input
        """
        if self.model is None or not feature_rows:
            return [{'ai_alert': 'N/A', 'ai_confidence': 0.0, 'ai_critical_prob': 0.0}
                    for _ in feature_rows]
        try:
            # Match the derived feature logic in the single-predict() method
            processed_rows = []
            for r in feature_rows:
                s = r.get('speed', 0.0)
                a = r.get('accel', 0.0)
                processed_row = r.copy()
                processed_row.update({
                    'speed_kmh': s * 3.6,
                    'abs_accel': abs(a),
                    'abs_yaw_rate': abs(r.get('yaw_rate', 0.0)),
                    'is_braking': 1 if a < -1.0 else 0,
                    'is_signaling': 1 if r.get('signals', 0) > 0 else 0,
                    'has_targets': 1 if r.get('num_targets', 0) > 0 else 0,
                    'speed_category': 0 if s < 5 else (1 if s < 20 else 2),
                    'closing_speed': r.get('rel_speed', 0.0),
                    'target_angle': r.get('target_angle', 0.0)
                })
                processed_rows.append({f: processed_row.get(f, 0) for f in self.features})
            
            X = pd.DataFrame(processed_rows)
            probs_matrix = self.model.predict_proba(X)  # shape: (N, 4)
            results = []
            for probs in probs_matrix:
                probs_list = probs.tolist()
                pred = int(probs.argmax())
                results.append({
                    'ai_alert':        self.label_map.get(pred, 'SAFE'),
                    'ai_confidence':   float(probs_list[pred]),
                    'ai_critical_prob': float(probs_list[3]) if len(probs_list) > 3 else 0.0,
                })
            return results
        except Exception as e:
            print(f"AI Batch Error: {e}")
            return [{'ai_alert': 'N/A', 'ai_confidence': 0.0, 'ai_critical_prob': 0.0}
                    for _ in feature_rows]

    def train(self, df: pd.DataFrame):
        self.model = train_model(df, model_out_path='test_model.json', report_out_path='test_report.json')
        self.features = FEATURE_COLS + DERIVED_FEATURES

BSDAIModel = BSDPredictor

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--collect", action="store_true", 
                        help="Run simulation to collect data before training")
    args = parser.parse_args()
    
    if args.collect:
        print("üì° Collecting training data via simulation...")
        import subprocess
        subprocess.run([sys.executable, "v2v_bsd_simulation.py", "--no-gui", "--steps", "3600"])
        print()
    
    train_model()
